<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>aagm</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="advances-and-applications-on-generative-deep-learning-models-aagm">Advances and Applications on Generative Deep Learning Models (AAGM)</h1>
<center><span>26 th November, 2019, Auckland, New Zealand </span></center>
<center><span>in conjunction to 5th Asian Conference on Pattern Recognition (ACPR) </span></center>
<center><span>Submission deadline: September 5</span></center>
<p><img src="bended.jpg" alt="bended"></p>
<hr>
<h2 id="motivation">Motivation</h2>
<p>To be effectively trained, deep neural networks require the support of large volumes of data. The quality, variety, and volume of the data are the great differentiator for obtaining a network with a high performance and does not with a mediocre performance. As in general, it is difficult to obtain databases that meet these characteristics, researchers have opted for developing models for data generation. Such generation models can be operated on modest databases, infer the underlying distribution of the data and can be used for generating new data.</p>
<p>The best models for estimating underlying probability densities of data are based at the same time on deep neural networks. A good variety of deep generative models have been proposed. Among such frameworks, Variational Autoencoders (VANs), Generative Antagonist Networks (GANs) and Autoregressive Models are prominent. The aforementioned models have advantages and disadvantages: VANs allow to efficiently compact data into low-dimensional latent spaces, but easily generate blurry samples; GANs allow one to generate data of very good quality, but they are in general difficult to be trained; Autoregressive models are simple and stable though limited to the generation of complex data.</p>
<h2 id="topics">Topics</h2>
<p>The estimation of underlying data density  is one of the most active areas in pattern recognition ; the models that can be sampled to generate synthetic data which is indistinguishable from real data.  For this workshop, we call for original papers focused on reporting advances in deep generative models, as well as the novel applications. Both, theoretical and practical contribution are welcome in related topics related, as</p>
<ul>
<li>New paradigms of Generative Models</li>
<li>Interpretability of Latent Variables</li>
<li>Multimodal Generator Models</li>
<li>Improvement in the computational efficiency and trainability of the generating models.</li>
<li>Exploring reinforcement learning supported by generative models.</li>
<li>Novel applications of generative models (though limited) such as denoising, super- resolution, and inpainting.</li>
<li>Compression and pruning generative models</li>
</ul>
<h2 id="author’s-information">Author’s Information</h2>
<p>Submitted papers should author blinded and do dot have been published, accepted or under review elsewhere. Non-peer reviewed media, such as Arxiv do not violate the terms.</p>
<p>Submissions need to follow the single-blind policy and be formatted in LNCS style, with a maximum of 14 pages (including references).</p>
<p>All the papers must be submitted using the provided templates.</p>
<ul>
<li>LaTeX2e Proceedings Templates <a href="ftp://ftp.springernature.com/cs-proceeding/llncs/llncs2e.zip">zip file</a>, <a href="https://www.overleaf.com/latex/templates/springer-lecture-notes-in-computer-science/kzwwpvhwnvfj#.WuA4JS5uZpi">Overleaf</a></li>
<li>Microsoft Word Proceedings Templates <a href="ftp://ftp.springernature.com/cs-proceeding/llncs/word/splnproc1703.zip">zip file</a>, <a href="https://resource-cms.springernature.com/springer-cms/rest/v1/content/7117506/data/v1">word 2013 zip file</a></li>
</ul>
<p>Workshop proceedings will be published after the conference in the CCIS series of Springer through the ACPR organizers (publication chair).</p>
<p><strong>NOTE</strong>: The registration fee for the workshop is included in the conference registration.</p>
<h2 id="important-dates">Important Dates</h2>
<ul>
<li>
<p>Paper <strong>Submission Deadline: September 5</strong>, 2019 (No Extension)<br>
<a href="https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2F3IAR2019"><strong>Submissions</strong></a></p>
</li>
<li>
<p>Notification to Authors:  September 25, 2019</p>
</li>
<li>
<p>Camera-Ready Deadline:  October 1, 2019</p>
</li>
<li>
<p>Workshop Date: November 26, 2019</p>
</li>
</ul>
<h2 id="schedule">Schedule</h2>
<p>Invited speaker: TBD<br>
Program:  TBD</p>
<h2 id="accepted-papers">Accepted Papers</h2>
<p>TBD</p>
<h2 id="organizing-committee">Organizing committee</h2>
<ul>
<li>Mariano Rivera, Center for Research in Mathematics AC, Mexico</li>
<li>Wei Qi Yan, Centre for Robotics &amp; Vision, Auckland University of Technology, New Zealand</li>
<li>Wangmeng Zuo, Harbin Institute of Technology, China</li>
<li>Adrián Pastor Lopez-Monroy, Center for Research in Mathematics AC, Mexico</li>
</ul>
</div>
</body>

</html>
